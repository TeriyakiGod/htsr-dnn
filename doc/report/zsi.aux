\relax 
\abx@aux@refcontext{nty/global//global/global}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Our goal}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Specific objectives}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Expected Outcomes}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Decision Boundary}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Definition}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Adaptability}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Optimization Impact}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Weights and Biases}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Initialization}{5}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Initialization of random biases and weights using Xavier/Glorot technique\relax }}{5}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:initialized_weights}{{1}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Weighted sum of inputs}{6}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The dot product of inputs and weights, representing the weighted sum of inputs\relax }}{6}{}\protected@file@percent }
\newlabel{fig:weighted_sum}{{2}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Our model}{7}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Architecture of our feedforward neural network model\relax }}{7}{}\protected@file@percent }
\newlabel{fig:model_architecture}{{3}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Activation functions}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Sigmoid function}{8}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Sigmoid function\relax }}{9}{}\protected@file@percent }
\newlabel{fig:sigmoid_function}{{4}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}The derivative of the sigmoid function}{9}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The derivative of the sigmoid function\relax }}{9}{}\protected@file@percent }
\newlabel{fig:sigmoid_derivativse_function}{{5}{9}}
\abx@aux@cite{0}{algorithms}
\abx@aux@segm{0}{0}{algorithms}
\@writefile{toc}{\contentsline {section}{\numberline {7}Gradient descent}{10}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Initialization a vector of zeros with the same length as the bias vector\relax }}{10}{}\protected@file@percent }
\newlabel{fig:initialized_cost_gradient}{{6}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The \texttt  {apply\_gradients} method in \texttt  {Neural network} class updates the weights and biases for each layer.\relax }}{10}{}\protected@file@percent }
\newlabel{fig:apply_gradients}{{7}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The \texttt  {apply\_gradients} method in \texttt  {Layer} class updates the weights and biases for a layer.\relax }}{11}{}\protected@file@percent }
\newlabel{fig:apply_gradients_on_layer}{{8}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Data loading}{12}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Data loading from mnist and creating a neural network\relax }}{12}{}\protected@file@percent }
\newlabel{fig:data_load}{{9}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Training the network}{13}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Training a neural network using a simple form of gradient descent on the MNIST dataset.\relax }}{13}{}\protected@file@percent }
\newlabel{fig:learn}{{10}{13}}
\abx@aux@cite{0}{ffn_wiki}
\abx@aux@segm{0}{0}{ffn_wiki}
\@writefile{toc}{\contentsline {section}{\numberline {10}Backpropagation}{14}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The \texttt  {backpropagate} function is part of the neural network training process.\relax }}{14}{}\protected@file@percent }
\newlabel{fig:backpropagation}{{11}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces The \texttt  {calculate\_gradients} method computes the gradients needed for the weight and bias adjustments.\relax }}{14}{}\protected@file@percent }
\newlabel{fig:calculate_gradients}{{12}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {11}Cost Landscape}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1}Definition}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2}Characteristics}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3}Impact on Optimization}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.4}Optimization Strategies}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12}Chain Rule}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1}Definition}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2}Application in Backpropagation}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13}Testing the network}{17}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1}Test Dataset}{17}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2}Example Code}{18}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3}Testing Results}{19}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.4}User Interface}{19}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces User interface for testing the neural network.\relax }}{19}{}\protected@file@percent }
\newlabel{fig:ui}{{13}{19}}
\@writefile{toc}{\contentsline {section}{\numberline {14}Conclusion}{20}{}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{nohash}
\abx@aux@read@bblrerun
\gdef \@abspage@last{21}
